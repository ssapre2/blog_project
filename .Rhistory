mutate(.pred_class = as.numeric(.pred_class))
# Align predictions to test dataset
predicted_df = augment(final_model,test_data) %>%
mutate(.pred_class = as.numeric(.pred_class)-1)
predicted_df %>%
roc_curve(truth = home_win,.pred_class) %>%
autoplot()
roc_auc(data = predicted_df$.pred_class,truth = predicted_df$home_win)
# Align predictions to test dataset
predicted_df = augment(final_model,test_data) %>%
mutate(.pred_class = as.numeric(.pred_class)-1)
roc_auc(data = predicted_df$.pred_class,truth = predicted_df$home_win)
predicted_df %>%
roc_curve(truth = home_win,.pred_class) %>%
autoplot()
final_full_wflow$.metrics
collect_metrics(fit_cv)
#fit_cv %>%
#  show_best(metric = "roc_auc") -> best_fit
##fit_cv %>%
#  show_best(metric = "accuracy")
final_wf = game_pred_wflow %>%
last_fit(splits)
final_model = extract_workflow(final_wf)
final_model %>%
extract_fit_engine() %>%
tidy() %>%
rename(penalty = lambda)
# Use final model to make prediction on test data set
predict(final_model,new_data = test_data)
# Align predictions to test dataset
predicted_df = augment(final_model,test_data)
# Align predictions to test dataset
predicted_df = augment(final_model,test_data)
# Extract model specs
final_model %>%
extract_spec_parsnip() -> final_specs
# Update workflow object and retrain on full training set
game_pred_wflow %>%
update_model(spec = final_specs) %>%
last_fit(splits) -> final_full_wflow
final_full_wflow$.metrics
# Extract model specs
final_model %>%
extract_spec_parsnip() -> final_specs
# Update workflow object and retrain on full training set
game_pred_wflow %>%
update_model(spec = final_specs) %>%
last_fit(splits) -> final_wflow
final_wflow$.metrics
predicted_df %>%
ggplot(aes(x = .pred, y = home_win)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
expand_limits(y = 0)
predicted_df %>%
ggplot(aes(x = .pred_class, y = home_win)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
expand_limits(y = 0)
predicted_df %>%
ggplot(aes(x = .pred_class, y = home_win)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red")
# Update workflow object and retrain on full training set
game_pred_wflow %>%
update_model(spec = final_specs) %>%
fit(data = cbind(training_data))
# Update workflow object and retrain on full training set
game_pred_wflow %>%
update_model(spec = final_specs) %>%
fit(data = cbind(train_data,test_data))
cbind(train_data,test_data)
# Update workflow object and retrain on full training set w/ same parameters
game_pred_wflow %>%
update_model(spec = final_specs) %>%
# Bind test and training data together
fit(data = cbind(train_data,test_data))
# Update workflow object and retrain on full training set w/ same parameters
game_pred_wflow %>%
update_model(spec = final_specs) %>%
# Bind test and training data together
fit(data = cbind(train_data,test_data)) -> final_obj
# Update workflow object and retrain on full training set w/ same parameters
game_pred_wflow %>%
update_model(spec = final_specs) %>%
# Bind test and training data together
fit(data = cbind(train_data,test_data)) %>%
extract_workflow() -> final_obj
# Update workflow object and retrain on full training set w/ same parameters
game_pred_wflow %>%
update_model(spec = final_specs) %>%
# Bind test and training data together
fit(data = cbind(train_data,test_data))-> final_obj
# Update workflow object and retrain on full training set w/ same parameters
game_pred_wflow %>%
update_model(spec = final_specs) %>%
# Bind test and training data together
fit(data = cbind(train_data,test_data))-> final_flow
class(final_flow)
extract_workflow(final_flow)
final_model %>%
save(file = "gamePred_model2024.rda")
# install and load packages
#install.packages("nflreadr")
library('nflreadr')
library('lme4')
library('caret')
library("tidyverse")
library('pROC')
# Scrape schedule Results
load_schedules(seasons = seq(2011,2024)) -> nfl_game_results
head(nfl_game_results)
# Scrape schedule Results
load_schedules(seasons = seq(2011,2024)) -> nfl_game_results
head(nfl_game_results)
nfl_game_results %>%
# Remove the upcoming season
filter(season < 2024) %>%
pivot_longer(cols = c(away_team,home_team),
names_to = "home_away",
values_to = "team") %>%
mutate(team_score = ifelse(home_away == "home_team",yes = home_score,no = away_score),
opp_score = ifelse(home_away == "home_team", away_score,home_score)) %>%  # sort for cumulative avg
arrange(season,week) %>%
select(season,game_id,team,team_score,opp_score,week) -> team_games
team_games %>%
arrange(week) %>%
group_by(season,team) %>%
mutate(cum_score_mean = cummean(team_score),
cum_score_opp = cummean(opp_score),
cum_wins = cumsum(team_score > opp_score),
cum_losses = cumsum(team_score < opp_score),
cum_ties = cumsum(team_score == opp_score),
cum_win_pct = cum_wins / (cum_wins + cum_losses),
cum_win_pct_lag_1 = lag(cum_win_pct,1),
cum_score_lag_1 = lag(cum_score_mean,1),
cum_opp_lag_1 = lag(cum_score_opp,1)
) %>%
# Non-lag variables leak info
select(week,game_id,contains('lag_1')) %>%
ungroup() -> cum_avgs
team_games %>%
arrange(week) %>%
group_by(season,team) %>%
mutate(cum_score_mean = cummean(team_score),
cum_score_opp = cummean(opp_score),
cum_wins = cumsum(team_score > opp_score),
cum_losses = cumsum(team_score < opp_score),
cum_ties = cumsum(team_score == opp_score),
cum_win_pct = cum_wins / (cum_wins + cum_losses),
cum_win_pct_lag_1 = lag(cum_win_pct,1),
cum_score_lag_1 = lag(cum_score_mean,1),
cum_opp_lag_1 = lag(cum_score_opp,1)
) %>%
# Non-lag variables leak info
select(week,game_id,contains('lag_1')) %>%
ungroup() -> cum_avgs
team_games %>%
group_by(season,team) %>%
summarise(wins = sum(team_score > opp_score),
losses = sum(team_score < opp_score),
ties = sum(team_score == opp_score))%>%
ungroup() %>%
arrange(season) %>%
group_by(team) %>%
mutate(win_pct = wins / (wins + losses),
lag1_win_pct = lag(win_pct,1)) %>%
ungroup() -> team_win_pct
dc = load_depth_charts(seq(2011,most_recent_season()))
injuries = load_injuries(seq(2011,most_recent_season()))
injuries %>%
filter(report_status == "Out") -> out_inj
dc %>%
filter(depth_team == 1) -> starters
starters %>%
select(-c(last_name,first_name,position,full_name)) %>%
inner_join(out_inj, by = c('season','club_code' = 'team','gsis_id','game_type','week')) -> injured_starters
# Number of injuries by position
injured_starters %>%
group_by(season,club_code,week,position) %>%
summarise(starters_injured = n()) %>%
ungroup() %>%
pivot_wider(names_from = position, names_prefix = "injured_",values_from = starters_injured) -> injuries_position
head(injuries_position)
nfl_game_results %>%
inner_join(cum_avgs, by = c('game_id','season','week','home_team' = 'team')) %>%
inner_join(cum_avgs, by = c('game_id','season','week','away_team' = 'team'),suffix = c('_home','_away'))-> w_avgs
# Check for stragglers
nfl_game_results %>%
anti_join(cum_avgs, by = c('game_id','season','home_team' = 'team','week')) -> unplayed_games
# Join previous season's results
#w_avgs %>%
#  left_join(team_win_pct,by = c('season','home_team' = 'team')) %>%
#  left_join(team_win_pct, by = c('away_team' = 'team','season'),suffix = c('_home','_away')) -> matchups
# Indicate whether home team won
w_avgs %>%
mutate(home_win = as.numeric(result > 0)) -> matchups
matchups %>%
left_join(injuries_position,by = c('season','home_team'='club_code','week')) %>%
left_join(injuries_position,by = c('season','away_team'='club_code','week'),suffix = c('_home','_away')) %>%
mutate(across(starts_with('injured_'), ~replace_na(.x, 0))) -> matchup_full
matchup_full %>%
select(-c(home_score,away_score,overtime,home_team,away_team,away_qb_name,home_qb_name,referee,stadium,home_coach,away_coach,ftn,espn,old_game_id,gsis,nfl_detail_id,pfr,pff,result)) -> matchup_ready
# Remove columns
matchup_ready = matchup_ready%>%
# Transform outcome into factor variable
select(where(is.numeric),game_id) %>%
mutate(home_win = as.factor(home_win))
# Split Data
#trainIndex <- createDataPartition(matchup_full$home_win, p = 0.7, list = FALSE)
#train_data <- matchup_full[trainIndex, ]
#test_data <- matchup_full[-trainIndex, ] %>%
# Remove first season for now
#  filter(season != 2011)
matchups24 = matchup_ready %>% filter(season == 2024)
splits = matchup_ready %>%
filter(season != 2024) %>%
initial_split(prop = 0.7)
train_data <- training(splits)
test_data  <- testing(splits)
colnames(train_data)
library(naniar)
gg_miss_var(x = train_data,show_pct = T)
library('tidymodels')
rec_impute = recipe(formula = home_win ~ .,
data = train_data) %>%
#create ID role (do not remove) game ID
update_role(game_id, new_role = "ID") %>%
#impute
#step_impute_median(starts_with('cum_'))
step_impute_median(all_numeric_predictors())
# Create recipe to for moneyline model
# Evalate imputation step
tidy(rec_impute, number = 1)
imp_models <- rec_impute %>%
check_missing(all_numeric_predictors()) %>%
prep(training = train_data)
# Check if imputation worked
imp_models %>%
bake(train_data) %>%
is.na() %>%
colSums()
tidy(imp_models,number = 1)
library('glmnet')
# Penalized Linear Regression
# Mixture = 1 means pure lasso
lr_mod <-
logistic_reg(mixture = 0.05,penalty = 1) %>%
set_engine("glmnet")
# Create folds for cross-validation
folds <- vfold_cv(train_data)
# create a workflow using recipe and model objects
game_pred_wflow <-
workflow() %>%
add_model(lr_mod) %>%
add_recipe(rec_impute)
fit_cv = game_pred_wflow %>%
fit_resamples(folds)
collect_metrics(fit_cv)
#fit_cv %>%
#  show_best(metric = "roc_auc") -> best_fit
##fit_cv %>%
#  show_best(metric = "accuracy")
final_wf = game_pred_wflow %>%
last_fit(splits)
#finalize_workflow(best_fit)
# final_fit <-
#   final_wf %>%
#   last_fit(split = splits)
final_model = extract_workflow(final_wf)
final_model %>%
extract_fit_engine() %>%
tidy() %>%
rename(penalty = lambda)
# Align predictions to test dataset
predicted_df = augment(final_model,test_data)
# Extract model specs
final_model %>%
extract_spec_parsnip() -> final_specs
# Update workflow object and retrain on full training set w/ same parameters
game_pred_wflow %>%
update_model(spec = final_specs) %>%
# Bind test and training data together
fit(data = cbind(train_data,test_data))-> final_flow
final_model %>%
save(file = "gamePred_model2024.rda")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nflreadr)
library(tidymodels)
library(nflfastR)
stats24 = load_player_stats(2024)
stats = load_player_stats(seasons = seq(2006,2023))
pbp23 = load_pbp(2023)
dc = load_depth_charts(season = seq(2016,most_recent_season())) %>% filter(position == 'WR',formation == 'Offense') %>%
select(season,recent_team = club_code,week,season_type = game_type,player_id = gsis_id,depth_team)
# Filter for wide receiver plays
wr_data <- stats %>%
filter(position == "WR") %>%
select(player_id,player_name,position,recent_team,season,week,season_type,
receptions:fantasy_points_ppr) %>%
# Receiving FP
mutate(rec_fp = (receiving_yards * 0.1) + (receiving_tds * 6) + (receptions * 0.5)) %>%
# Add depth chart status since we don't have participation data
left_join(y = dc,by = c('player_id','week','season','season_type',"recent_team")) %>%
# Only first 3 are counted so some players are NA'd if they're below 3rd on DC
replace_na(list(depth_team = '4')) %>%
mutate(depth_team = as.numeric(depth_team))
read.csv('https://github.com/ffverse/ffopportunity/releases/download/latest-data/ep_weekly_2024.csv') -> ff_2024
ff_2024 %>% filter(position == 'WR') %>% select(game_id,player_id,season,rec_fantasy_points,rec_fantasy_points_exp) %>%
metrics(truth = rec_fantasy_points,estimate = rec_fantasy_points_exp)
library(naniar)
gg_miss_case(wr_data)
gg_miss_var(wr_data)
wr_data %>%
select(racr,air_yards_share,wopr,target_share,receiving_epa) -> df_miss
df_miss %>%
gg_miss_upset()
# What if we take out racr?
# Create Time Weighting
weighted_avg = function(metric_vector){
# Take in sliding window of vector of chosen metric
n = length(metric_vector)
# Create Weights for each value based on recency
weights = seq(1,n)
# Calculated weighted average
w_avg = sum(metric_vector * weights) / sum(weights)
return(w_avg)
}
library(TTR)
library(slider)
wr_data %>%
# Should remove most missingness
filter(!is.na(racr)) %>%
group_by(player_id,season) %>%
arrange(week) %>%
# Weighted Avg (moving)
# Take lag so we are not leaking any data
mutate(across(receptions:depth_team, ~ lag(slide_dbl(.x,.f = weighted_avg,.before = Inf,.complete = TRUE)),.names = "wt_{col}")) %>%
ungroup() %>%
# Convert negative fantasy points to 0
mutate(fantasy_points_target = ifelse(fantasy_points < 0,0,fantasy_points),
log_fantasy_points = log(fantasy_points_target + 1)) %>%
# Need data, don't use week 1 for now
filter(week > 1) -> ma_wr
# Calculate the correlation matrix
cor_matrix <- ma_wr %>%
select(starts_with("wt_"), fantasy_points_target) %>%
cor(use = "complete.obs")
# Reshape the correlation matrix for ggplot
cor_data <- reshape2::melt(cor_matrix)
ggplot(data = cor_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1,1), name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
labs(title = "Correlation Matrix of Dataset", x = "", y = "")
ma_wr %>%
ggplot(aes(x = fantasy_points_target)) +
geom_histogram()
ma_wr %>%
ggplot(aes(x = log_fantasy_points)) +
geom_histogram()
library(tidymodels)
# Split
set.seed(222)
# Put 3/4 of the data into the training set
data_split <- ma_wr %>%
# Don't use first week
filter(week >1)%>%
# Filter on relevant columns
select(starts_with('wt_'),log_fantasy_points,player_id,season,week,recent_team,
fantasy_points,fantasy_points_ppr) %>%
# make split
initial_split( prop = 3/4)
# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
wt_recipe = train_data %>%
recipe(fantasy_points_target ~ .,) %>%
update_role(c(player_id,recent_team,fantasy_points,fantasy_points_ppr),new_role = 'ID') %>%
# Generally not recommended to throw out all data, but for brevity, let's remove NAs
step_naomit(all_numeric_predictors()) %>%
# Remove zero variance predictors (ie. variables that contribute nothing to prediction)
step_center(all_numeric_predictors()) %>%
step_BoxCox()
wt_recipe = train_data %>%
recipe(fantasy_points_target ~ .,) %>%
update_role(c(player_id,recent_team,fantasy_points,fantasy_points_ppr),new_role = 'ID') %>%
# Generally not recommended to throw out all data, but for brevity, let's remove NAs
step_naomit(all_numeric_predictors()) %>%
# Remove zero variance predictors (ie. variables that contribute nothing to prediction)
step_center(all_numeric_predictors())
library(tidymodels)
# Split
set.seed(222)
# Put 3/4 of the data into the training set
data_split <- ma_wr %>%
# Don't use first week
filter(week >1)%>%
# Filter on relevant columns
select(starts_with('wt_'),fantasy_points_target,player_id,season,week,recent_team,
fantasy_points,fantasy_points_ppr) %>%
# make split
initial_split( prop = 3/4)
# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
wt_recipe = train_data %>%
recipe(fantasy_points_target ~ .,) %>%
update_role(c(player_id,recent_team,fantasy_points,fantasy_points_ppr),new_role = 'ID') %>%
# Generally not recommended to throw out all data, but for brevity, let's remove NAs
step_naomit(all_numeric_predictors()) %>%
# Remove zero variance predictors (ie. variables that contribute nothing to prediction)
step_center(all_numeric_predictors())
#
summary(wt_recipe)
test_data %>%
filter(!is.na(wt_receptions)) -> test_data
sum(colSums(is.na(test_data)))
exp_recipe = train_data  %>%
recipe(log_fantasy_points ~ .,) %>%
update_role(c(player_id,recent_team,fantasy_points,fantasy_points_ppr),new_role = 'ID') %>%
# Generally not recommended to throw out all data, but for brevity, let's remove NAs
step_naomit(all_numeric_predictors()) %>%
# Remove zero variance predictors (ie. variables that contribute nothing to prediction)
step_zv(all_predictors()) %>%
step_center(all_numeric_predictors())
exp_recipe = train_data  %>%
recipe(fantasy_points_target ~ .,) %>%
update_role(c(player_id,recent_team,fantasy_points,fantasy_points_ppr),new_role = 'ID') %>%
# Generally not recommended to throw out all data, but for brevity, let's remove NAs
step_naomit(all_numeric_predictors()) %>%
# Remove zero variance predictors (ie. variables that contribute nothing to prediction)
step_zv(all_predictors()) %>%
step_center(all_numeric_predictors())
#summary(exp_recipe)
# Specify a penalized GLM model with tuning parameters
glm_model <- linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet")
# Define the parameter grid
param_grid <- grid_regular(penalty(), mixture(), levels = 10)  # Adjust levels as needed
# Set up cross-validation folds
cv_folds <- vfold_cv(train_data, v = 5)
# Create a workflow
workflow <- workflow() %>%
add_recipe(exp_recipe) %>%
add_model(glm_model)
# Tune the model
tuned_results <- tune_grid(
workflow,
resamples = cv_folds,
grid = param_grid
)
library(glmnet)
#library(lightgbm)
#library(bonsai)
glm_spec <- linear_reg(
penalty = tune(),     # Lambda (regularization strength)
mixture = tune(),    # Alpha (0 = Ridge, 1 = Lasso, values in between = Elastic Net)
) %>%
set_engine("glmnet")
glm_wflow <-
workflow() %>%
add_recipe(exp_recipe) %>%
add_model(glm_spec)
wr_folds <- vfold_cv(train_data, v = 5)
# Tune the hyperparameters using a grid of values
glm_tune_results <- tune_grid(
glm_wflow,
resamples = wr_folds,
grid = 10   # Number of tuning combinations to evaluate
)
# Show the tuning results
tuned_results %>%
collect_metrics() %>%
filter(.metric == "rmse") %>%
arrange(mean)
glm_tune_results %>%
collect_metrics() %>%
filter(.metric == "rmse") %>%
arrange(mean)
# Display tuning results
glm_tune_results %>%
collect_metrics() %>%
filter(.metric == "rmse") %>%
arrange(mean)
par(mfrow = c(2, 2))
plot(final_glm_fit)
# Select the best hyperparameters based on RMSE
best_glm <- select_best(glm_tune_results, metric = 'rmse')
# Finalize the workflow with the best hyperparameters
final_glm_workflow <- finalize_workflow(glm_wflow, best_glm)
best_glm
# Fit the finalized model on the entire training data
final_glm_fit <- fit(final_glm_workflow, data = train_data)
# Make predictions on the test set
glm_predictions <- augment(final_glm_fit, new_data = test_data)
# Evaluate the model's performance (RMSE)
glm_metrics <- glm_predictions %>%
metrics(truth = fantasy_points_target, estimate = .pred)
# Print the evaluation metrics
print(glm_metrics)
glm_predictions %>%
mutate(resid = fantasy_points_target - .pred) %>%
ggplot(aes(x = resid)) +
geom_histogram()
par(mfrow = c(2, 2))
plot(final_glm_fit)
final_glm_fit$fit
final_glm_fit$fit$fit$fit
