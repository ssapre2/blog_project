---
title: "Predicting NFL Game Outcomes with nflfastR"
author: "Sameer Sapre"
date: "2024-06-30"
categories: [news, code, analysis]
image: "nflfastR.png"
execute: 
  warning: false
page-layout: full
  
---

## Intro

Hello everyone! Today I want to share a quick tutorial on using `nflreadR` to build a simple game outcome model.

First, a quick introduction of `nflreadR` - it's part of the `nflverse` family of packages in R that all easily and efficiently obtaining data from NFL games. In this post, we'll be using its suite of functions to get the data we need to build a predictive model.

First, let's load in some important packages. We'll load in the `tidyverse` for data cleaning and manipulation. The `caret` and `lme4` packages for our model-building.

```{r}
# install and load packages
#install.packages("nflreadr")
library('nflreadr')
library('lme4')
library('caret')
library("tidyverse")
library('pROC')

```

## Load Data

Now that we have the relevant packages loaded, let's get started getting our data together. Starting with game data, we'll pull game results from 2011 - 2021. Here, we see that we get a schedule where each row (record) represents a game. There's a home and away team, corresponding scores, and more for each game.

```{r}
# Scrape schedule Results
load_schedules(seasons = seq(2011,2024)) -> nfl_game_results 
head(nfl_game_results)
```


We've loaded our schedules in with some interesting variables to use in our model. However, it's not quite in the format we need it to be. Ideally, we'd like to feed in 2 games and have the model give us a winner.

```{r}
nfl_game_results %>%
  # Remove the upcoming season
  filter(season < 2024) %>%
  pivot_longer(cols = c(away_team,home_team),
               names_to = "home_away",
               values_to = "team") %>%
  mutate(team_score = ifelse(home_away == "home_team",yes = home_score,no = away_score),
         opp_score = ifelse(home_away == "home_team", away_score,home_score)) %>%  # sort for cumulative avg
  arrange(season,week) %>%
  select(season,game_id,team,team_score,opp_score,week) -> team_games
```

Let's use `pivot_longer()` to rearrange our dataset and select some simple variables before making the matchup set.

## Feature Engineering

Our goal is to be able to predict the outcome of each. To do that, we need to think about what impacts the outcome of a game before teams even take the field. 

In the case of an NFL game it could things like player skill level, how far a team has to travel, injuries, even the food that players ate the night before. Using `nflreadr` we can see that there are tons of features we could see impacting the game such as .....


First, let's start with what I think could have the biggest impact on ... team strength! 

There are several ways to quantify team strength, some more complex then others, but for this quick tutorial, we will use recent results as a measure of team strength. The results will be in the form of Cumulative points scored/allowed and winning percentage leading up to the game.

Then, we'll create some features...

First, cumulative points.

```{r}
team_games %>%
  arrange(week) %>%
  group_by(season,team) %>%
  mutate(cum_score_mean = cummean(team_score),
          cum_score_opp = cummean(opp_score),
          cum_wins = cumsum(team_score > opp_score),
          cum_losses = cumsum(team_score < opp_score),
          cum_ties = cumsum(team_score == opp_score),
         cum_win_pct = cum_wins / (cum_wins + cum_losses),
         cum_win_pct_lag_1 = lag(cum_win_pct,1),
         cum_score_lag_1 = lag(cum_score_mean,1),
         cum_opp_lag_1 = lag(cum_score_opp,1)
         ) %>%
  # Non-lag variables leak info
  select(week,game_id,contains('lag_1')) %>%
  ungroup() -> cum_avgs
```


Win percentage.

```{r ignore = TRUE}
team_games %>%
  group_by(season,team) %>%
  summarise(wins = sum(team_score > opp_score),
            losses = sum(team_score < opp_score),
            ties = sum(team_score == opp_score))%>%
  ungroup() %>%
  arrange(season) %>%
  group_by(team) %>%
  mutate(win_pct = wins / (wins + losses),
         lag1_win_pct = lag(win_pct,1)) %>%
  ungroup() -> team_win_pct
```

This should be a good start, but I still feel like something is missing. If I'm trying to predict who will win the game, I want to see the injury report. I want to know who's actually in the game. Thankfully `nflreadr` provides that info.

First, we load in depth charts and injury info because we want to know who will be injured, but also if they play an important role on their team. While it would be helpful to know which Niners RBs are out, it would probably helpful know if it's CMc or not.


```{r}
dc = load_depth_charts(seq(2011,most_recent_season()))
injuries = load_injuries(seq(2011,most_recent_season()))
```


```{r}
injuries %>%
  filter(report_status == "Out") -> out_inj

dc %>% 
  filter(depth_team == 1) -> starters

starters %>%
  select(-c(last_name,first_name,position,full_name)) %>%
  inner_join(out_inj, by = c('season','club_code' = 'team','gsis_id','game_type','week')) -> injured_starters

# Number of injuries by position
injured_starters %>%
  group_by(season,club_code,week,position) %>%
  summarise(starters_injured = n()) %>%
  ungroup() %>%
  pivot_wider(names_from = position, names_prefix = "injured_",values_from = starters_injured) -> injuries_position

head(injuries_position)

```

Alright, now we have some flags for injured starter at each position. Coming up, we need to bring all of our new features together.

## Joins

```{r}
nfl_game_results %>%
  inner_join(cum_avgs, by = c('game_id','season','week','home_team' = 'team')) %>%
  inner_join(cum_avgs, by = c('game_id','season','week','away_team' = 'team'),suffix = c('_home','_away'))-> w_avgs

# Check for stragglers
nfl_game_results %>%
  anti_join(cum_avgs, by = c('game_id','season','home_team' = 'team','week')) -> unplayed_games

# Join previous season's results
#w_avgs %>%
#  left_join(team_win_pct,by = c('season','home_team' = 'team')) %>%
#  left_join(team_win_pct, by = c('away_team' = 'team','season'),suffix = c('_home','_away')) -> matchups
```


```{r}

# Indicate whether home team won
w_avgs %>%
  mutate(home_win = as.numeric(result > 0)) -> matchups
```


Now, let's bring in our injury data.

```{r}
matchups %>%
  left_join(injuries_position,by = c('season','home_team'='club_code','week')) %>%
  left_join(injuries_position,by = c('season','away_team'='club_code','week'),suffix = c('_home','_away')) %>%
  mutate(across(starts_with('injured_'), ~replace_na(.x, 0))) -> matchup_full
```



And ... BOOM! We have a dataset with game matchups and some features to start out. Feel free to peruse the data to find potential features to include in our Model. 


# Building the Model

Before we do any preprocessing, let's split the data.

First let's remove columns that might leak info to the model. Remember the model must only use information available prior to kickoff. We also want to remove some hi

```{r}
matchup_full %>%
  select(-c(home_score,away_score,overtime,home_team,away_team,away_qb_name,home_qb_name,referee,stadium,home_coach,away_coach,ftn,espn,old_game_id,gsis,nfl_detail_id,pfr,pff,result)) -> matchup_ready
```


Looks like there are a few varibles with several na's. Though we'd like to keep the "lag" columns that we created. 

```{r}
# Remove columns
matchup_ready = matchup_ready%>%
  # Transform outcome into factor variable
  select(where(is.numeric),game_id) %>% 
  mutate(home_win = as.factor(home_win)) 
```

What about other NAs? There are still some left. For the purpose of this exercise, let's remove them with na.omit(). This is a bad idea as it leaves potentially useful data on the table.


```{r}
# Split Data
#trainIndex <- createDataPartition(matchup_full$home_win, p = 0.7, list = FALSE)
#train_data <- matchup_full[trainIndex, ]
#test_data <- matchup_full[-trainIndex, ] %>%
  # Remove first season for now
#  filter(season != 2011)
splits = initial_split(matchup_ready)
train_data <- training(splits)
test_data  <- testing(splits)
```


Let's checkout the variables avaialable to us.

```{r}
colnames(train_data)
```
Off the bat we see a lot of variables that we ourselves created. Do we really need that many variables tracking injured players? Probably not, but let's continue with them for now.


Alright, now that we have our training data ready, let's leverage the power of `tidymodels` to continue our preprocessing. I'm sure, you noticed quite a few variables still containing missing values.

Let's check the missingness of our training data using `naniar`.


```{r}
library(naniar)

gg_miss_var(x = train_data,show_pct = T)

```

It looks like our custom variables have some missingess as well as some wind and temperature variables.


```{r}
library('tidymodels')

rec_impute = recipe(formula = home_win ~ .,
                 data = train_data) %>%
  #create ID role (do not remove) game ID
  update_role(game_id, new_role = "ID") %>%
  #impute
  #step_impute_median(starts_with('cum_'))
  step_impute_median(starts_with('cum_'),'wind','temp')

# Create recipe to for moneyline model

# Evalate imputation step
tidy(rec_impute, number = 1)

```

```{r}
imp_models <- prep(rec_impute, training = train_data)

tidy(imp_models,number = 1)
```



## Modeling 

Ahh finally, now we can get to the actual model building.... which we'll do in about 3 lines of code.

```{r}
library('glmnet')
# Penalized Linear Regression
# Mixture = 1 means pure lasso
lr_mod <- 
  logistic_reg(mixture = 0.05,penalty = 1) %>% 
  set_engine("glmnet")

```

And that's it! We'll start off with a basic logistic regression. With a few tunable (though we won't be tuning in this post) parameters

```{r}
# Create folds for cross-validation
folds <- vfold_cv(train_data)
```


```{r}
# create a workflow using recipe and model objects
game_pred_wflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(rec_impute)

```




```{r}

prep(rec_impute,training = train_data)

fit_cv = game_pred_wflow %>%
  fit_resamples(folds)

```

Check for best model fit. It looks like using ROC-AUC and accuracy agree that the first model is the best. We


```{r}
collect_metrics(fit_cv)
fit_cv %>%
  show_best(metric = "roc_auc") -> best_fit

fit_cv %>%
  show_best(metric = "accuracy") 
```


Extract best model fit.


```{r}
final_wf = game_pred_wflow %>%
  finalize_workflow(best_fit)
```


```{r}
final_fit <- 
  final_wf %>%
  last_fit(split = splits) 
```


```{r}
final_fit %>%
  extract_fit_engine() %>%
  tidy() %>%
  rename(penalty = lambda)
```




```{r}
# Use model to make prediction on test data set
predict(fit_cv,new_data = test_data)

# Select best model based on ROC-AUC score
fit_cv %>%
  select_best(metric = "roc_auc") -> best_fit

best_fit$.config %>%
  collect_predictions()


game_aug = augment(best_fit$.config,test_data)



game_aug %>%
  select(week,season,home_team,away_team,.pred_TRUE,home_win,home_score,away_score) %>%
  arrange(desc(.pred_TRUE))
```


```{r}
game_aug %>% 
  roc_curve(truth = home_win, .pred_TRUE) %>% 
  autoplot()


game_aug %>% select(.pred_class,home_win)
# Plot results by week
game_aug %>%
  group_by(week) %>%
  summarise(acc = sum(.pred_class== home_win)/n(), n= n()) -> acc_by_week

acc_by_week

acc_by_week %>%
  ggplot(aes(x = week, y = acc)) +
  geom_col()

game_aug %>%
  group_by(season) %>%
  summarise(acc = sum(.pred_class== home_win)/n(), n= n()) -> acc_by_season

acc_by_season

acc_by_season %>%
  ggplot(aes(x = season, y = acc)) +
  geom_col()
```

Looks like predictions get slightly stronger throughout season. Sample size is small for end of season.

Ooof! this is a terrible fit. Let's check the model fit.

```{r}
game_aug %>% 
  roc_auc(truth = home_win, .pred_TRUE)
```

Let's create a new model recipe to check how other models do

```{r}
rec_moneyline = recipe(formula = home_win ~
                      game_id +home_moneyline,
                 data = train_data) %>%
  #create ID role (do not remove) game ID
  update_role(game_id, new_role = "ID")

# Update workflow
game_pred_wflow %>%
  update_recipe(rec_moneyline) -> ml_flow

prep(rec_moneyline,training = train_data)

ml_fit <- 
  ml_flow %>% 
  fit(data = train_data)

extract_fit_parsnip(ml_fit) %>%
  tidy() 


# Make predictions
predict(ml_fit,new_data = test_data)

# Augment dataframe with preds
ml_aug = augment(ml_fit,test_data)

# Plot ROC
ml_aug %>% 
  roc_curve(truth = home_win, .pred_TRUE) %>% 
  autoplot()

ml_aug %>% 
  roc_auc(truth = home_win, .pred_TRUE)
```






